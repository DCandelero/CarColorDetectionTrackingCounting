{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BO5pbRvAIDQa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAtKqeQ4Sapw"
      },
      "source": [
        "# Play video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cap = cv2.VideoCapture('Data/drone_video_treino.mp4')\n",
        "# print(cap.isOpened())\n",
        "\n",
        "# while(cap.isOpened()):\n",
        "#     ret, frame = cap.read()\n",
        "    \n",
        "#     resizedFrame = cv2.resize(frame, (960, 540))\n",
        "\n",
        "#     try:\n",
        "#         cv2.imshow(\"resizedFrame\", resizedFrame)\n",
        "#     except:\n",
        "#         print(\"Can't show image!\")\n",
        "#         break\n",
        "\n",
        "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHFEyp9sSlxi"
      },
      "source": [
        "# Detectors\n",
        "Here we will use two different methods of detection.\n",
        "- Haar Cascade: Is usually faster than most methods but do not have a great accuracy. It's important to notice that most images in the training set is images of the front and the side of the vehicles. So this is why the method performs poorly here.\n",
        "- YOLO (You Only Look Once): Deep learning model trained on the COCO dataset. Robust model and preety accurate but is slower than haar cascade. This one performs the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ5onu3MS2-q"
      },
      "source": [
        "## Haar cascade without tracker\n",
        "- Poorly vehicles detection (detect stones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3OX2ifN2SpLr"
      },
      "outputs": [],
      "source": [
        "# cap = cv2.VideoCapture('Data/Traffic_Example.mp4')\n",
        "\n",
        "# car_cascade = cv2.CascadeClassifier('./detectors/car.xml')\n",
        "\n",
        "# trackers = cv2.legacy.MultiTracker_create()\n",
        "\n",
        "# count=0\n",
        "# while(cap.isOpened()):\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if (count % 50 == 0):\n",
        "#         trackers = cv2.legacy.MultiTracker_create()\n",
        "#         cars = car_cascade.detectMultiScale(frame)\n",
        "#         for car in cars:\n",
        "#             (x, y, w, h) = [int(v) for v in car]\n",
        "#             cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "            \n",
        "#             # Track object\n",
        "#             tracker = cv2.legacy.TrackerKCF_create()\n",
        "#             trackers.add(tracker, frame, (x,y,w,h))\n",
        "#     else:\n",
        "#         success, boxes = trackers.update(frame)\n",
        "#         for box in boxes:\n",
        "#             (x, y, w, h) = [int(v) for v in box]\n",
        "#             cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
        "#     count += 1\n",
        "\n",
        "#     cars = car_cascade.detectMultiScale(frame)\n",
        "#     for car in cars:\n",
        "#         (x, y, w, h) = [int(v) for v in car]\n",
        "#         cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "\n",
        "\n",
        "#     # Display result ----------------------------------------------------------------------------\n",
        "#     resizedFrame = cv2.resize(frame, (960, 540))\n",
        "#     cv2.imshow(\"frame\", resizedFrame)\n",
        "\n",
        "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NF2FZ2oS5U6"
      },
      "source": [
        "## YOLO detector without tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y_wDxvndXTwX"
      },
      "outputs": [],
      "source": [
        "# Download yolo weights\n",
        "import requests\n",
        "url = 'https://drive.google.com/file/d/1arP01Q6KCFSRsqLbz8NilCKBU-ulj2dD/view?usp=sharing'\n",
        "r = requests.get(url)\n",
        "open('Data/yolov3.weights', 'wb').write(r.content)\n",
        "\n",
        "with open(\"./Detectors/coco_classes.txt\", 'r') as classes_file:\n",
        "    CLASSES = dict(enumerate([line.strip() for line in classes_file.readlines()]))\n",
        "with open(\"./Detectors/coco_classes_of_interest.txt\", 'r') as coi_file:\n",
        "    CLASSES_OF_INTEREST = tuple([line.strip() for line in coi_file.readlines()])\n",
        "conf_threshold = 0.5\n",
        "net = cv2.dnn.readNet(\"./Detectors/yolov3.weights\", \"./Detectors/yolov3.cfg\")\n",
        "\n",
        "def get_bounding_boxes(image):\n",
        "    '''\n",
        "    Return a list of bounding boxes of objects detected,\n",
        "    their classes and the confidences of the detections made.\n",
        "    '''\n",
        "\n",
        "    # create image blob\n",
        "    scale = 0.00392\n",
        "    image_blob = cv2.dnn.blobFromImage(image, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    # detect objects\n",
        "    net.setInput(image_blob)\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = []\n",
        "    for i in net.getUnconnectedOutLayers():\n",
        "        output_layers.append(layer_names[i - 1])\n",
        "    outputs = net.forward(output_layers)\n",
        "\n",
        "    classes = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > conf_threshold and CLASSES[class_id] in CLASSES_OF_INTEREST:\n",
        "                width = image.shape[1]\n",
        "                height = image.shape[0]\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                classes.append(CLASSES[class_id])\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "    # remove overlapping bounding boxes\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "\n",
        "    _bounding_boxes = []\n",
        "    _classes = []\n",
        "    _confidences = []\n",
        "    for i in indices:\n",
        "        _bounding_boxes.append(boxes[i])\n",
        "        _classes.append(classes[i])\n",
        "        _confidences.append(confidences[i])\n",
        "\n",
        "    return _bounding_boxes, _classes, _confidences\n",
        "\n",
        "# cap = cv2.VideoCapture('Data/Traffic_Example.mp4')\n",
        "# print(cap.isOpened())\n",
        "\n",
        "# while(cap.isOpened()):\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     _bounding_boxes, _classes, _confidences = get_bounding_boxes(frame)\n",
        "\n",
        "#     for box in _bounding_boxes:\n",
        "#         (x, y, w, h) = [int(v) for v in box]\n",
        "#         cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "\n",
        "#     resizedFrame = cv2.resize(frame, (960, 540))\n",
        "#     cv2.imshow(\"frame\", resizedFrame)\n",
        "\n",
        "\n",
        "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHNFqSx4X4Gx"
      },
      "source": [
        "# Tracker\n",
        "- All tracker function used in the application\n",
        "- Tracker utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BGlIFoxIX61f"
      },
      "outputs": [],
      "source": [
        "def add_new_blobs(boxes, classes, confidences, blobs, frame, mcdf):\n",
        "    matched_blob_ids = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        _type = classes[i] if classes is not None else None\n",
        "        _confidence = confidences[i] if confidences is not None else None\n",
        "        _tracker =  cv2.TrackerKCF_create()\n",
        "        _tracker.init(frame, tuple(box))\n",
        "\n",
        "        match_found = False\n",
        "        for _id, blob in blobs.items():\n",
        "            if get_overlap(box, blob.bounding_box) >= 0.6:\n",
        "                match_found = True\n",
        "                if _id not in matched_blob_ids:\n",
        "                    blob.num_consecutive_detection_failures = 0\n",
        "                    matched_blob_ids.append(_id)\n",
        "                blob.update(box, _type, _confidence, _tracker)\n",
        "\n",
        "\n",
        "        if not match_found:\n",
        "            _blob = Blob(box, _type, _confidence, _tracker)\n",
        "            blob_id = generate_object_id()\n",
        "            blobs[blob_id] = _blob\n",
        "\n",
        "    blobs = _remove_stray_blobs(blobs, matched_blob_ids, mcdf)\n",
        "    return blobs\n",
        "\n",
        "def remove_duplicates(blobs):\n",
        "    for blob_id, blob_a in list(blobs.items()):\n",
        "        for _, blob_b in list(blobs.items()):\n",
        "            if blob_a == blob_b:\n",
        "                break\n",
        "\n",
        "            if get_overlap(blob_a.bounding_box, blob_b.bounding_box) >= 0.6 and blob_id in blobs:\n",
        "                del blobs[blob_id]\n",
        "    return blobs\n",
        "\n",
        "def update_blob_tracker(blob, blob_id, frame):\n",
        "    '''\n",
        "    Update a blob's tracker object.\n",
        "    '''\n",
        "    success, box = blob.tracker.update(frame)\n",
        "    if success:\n",
        "        blob.num_consecutive_tracking_failures = 0\n",
        "        blob.update(box)\n",
        "    else:\n",
        "        blob.num_consecutive_tracking_failures += 1\n",
        "\n",
        "    return (blob_id, blob)\n",
        "\n",
        "def _remove_stray_blobs(blobs, matched_blob_ids, mcdf):\n",
        "    '''\n",
        "    Remove blobs that \"hang\" after a tracked object has left the frame.\n",
        "    '''\n",
        "    for blob_id, blob in list(blobs.items()):\n",
        "        if blob_id not in matched_blob_ids:\n",
        "            blob.num_consecutive_detection_failures += 1\n",
        "        if blob.num_consecutive_detection_failures > mcdf:\n",
        "            del blobs[blob_id]\n",
        "    return blobs\n",
        "\n",
        "class Blob:\n",
        "    '''\n",
        "    A blob represents a tracked object as it moves around in a video.\n",
        "    '''\n",
        "    def __init__(self, _bounding_box, _type, _confidence, _tracker):\n",
        "        self.bounding_box = _bounding_box\n",
        "        self.type = _type\n",
        "        self.type_confidence = _confidence\n",
        "        self.centroid = get_centroid(_bounding_box)\n",
        "        self.area = get_area(_bounding_box)\n",
        "        self.tracker = _tracker\n",
        "        self.num_consecutive_tracking_failures = 0\n",
        "        self.num_consecutive_detection_failures = 0\n",
        "        self.crossed_counting_line = False\n",
        "        self.position_first_detected = tuple(self.centroid)\n",
        "\n",
        "    def update(self, _bounding_box, _type=None, _confidence=None, _tracker=None):\n",
        "        self.bounding_box = _bounding_box\n",
        "        self.type = _type if _type is not None else self.type\n",
        "        self.type_confidence = _confidence if _confidence is not None else self.type_confidence\n",
        "        self.centroid = get_centroid(_bounding_box)\n",
        "        self.area = get_area(_bounding_box)\n",
        "        if _tracker:\n",
        "            self.tracker = _tracker\n",
        "\n",
        "\n",
        "'''\n",
        "# Bounding box utility functions.\n",
        "'''\n",
        "\n",
        "def get_centroid(bbox):\n",
        "    # Calculates the center point of a bounding box.\n",
        "    x, y, w, h = bbox\n",
        "    return (round((x + x + w) / 2), round((y + y + h) / 2))\n",
        "\n",
        "def get_area(bbox):\n",
        "    '''\n",
        "    Calculates the area of a bounding box.\n",
        "    '''\n",
        "    _, _, w, h = bbox\n",
        "    return w * h\n",
        "\n",
        "def get_overlap(bbox1, bbox2):\n",
        "    '''\n",
        "    Calculates the degree of overlap of two bounding boxes.\n",
        "    This can be any value from 0 to 1 where 0 means no overlap and 1 means complete overlap.\n",
        "    The degree of overlap is the ratio of the area of overlap of two boxes and the area of the smaller box.\n",
        "    '''\n",
        "    bbox1_x1 = bbox1[0]\n",
        "    bbox1_y1 = bbox1[1]\n",
        "    bbox1_x2 = bbox1[0] + bbox1[2]\n",
        "    bbox1_y2 = bbox1[1] + bbox1[3]\n",
        "\n",
        "    bbox2_x1 = bbox2[0]\n",
        "    bbox2_y1 = bbox2[1]\n",
        "    bbox2_x2 = bbox2[0] + bbox2[2]\n",
        "    bbox2_y2 = bbox2[1] + bbox2[3]\n",
        "\n",
        "    overlap_x1 = max(bbox1_x1, bbox2_x1)\n",
        "    overlap_y1 = max(bbox1_y1, bbox2_y1)\n",
        "    overlap_x2 = min(bbox1_x2, bbox2_x2)\n",
        "    overlap_y2 = min(bbox1_y2, bbox2_y2)\n",
        "\n",
        "    overlap_width = overlap_x2 - overlap_x1\n",
        "    overlap_height = overlap_y2 - overlap_y1\n",
        "\n",
        "    if overlap_width < 0 or overlap_height < 0:\n",
        "        return 0.0\n",
        "\n",
        "    overlap_area = overlap_width * overlap_height\n",
        "\n",
        "    bbox1_area = (bbox1_x2 - bbox1_x1) * (bbox1_y2 - bbox1_y1)\n",
        "    bbox2_area = (bbox2_x2 - bbox2_x1) * (bbox2_y2 - bbox2_y1)\n",
        "    smaller_area = bbox1_area if bbox1_area < bbox2_area else bbox2_area\n",
        "\n",
        "    epsilon = 1e-5 # small value to prevent division by zero\n",
        "    overlap = overlap_area / (smaller_area + epsilon)\n",
        "    return overlap\n",
        "\n",
        "def generate_object_id():\n",
        "    return 'obj_' + uuid.uuid4().hex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoJjhlFuYUr4"
      },
      "source": [
        "# Counter\n",
        "- Counter util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5xzruGBHYWW7"
      },
      "outputs": [],
      "source": [
        "def _line_segments_intersect(line1, line2):\n",
        "    def get_orientation(p, q, r):\n",
        "        val = (q[1] - p[1]) * (r[0] - q[0]) - (q[0] - p[0]) * (r[1] - q[1])\n",
        "        if val == 0:\n",
        "            return 0\n",
        "        return 1 if val > 0 else 2\n",
        "\n",
        "    def is_on_segment(p, q, r):\n",
        "        if q[0] <= max(p[0], r[0]) and q[0] >= min(p[0], r[0]) and \\\n",
        "            q[1] <= max(p[1], r[1]) and q[1] >= min(p[1], r[1]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    p1 = line1[0]\n",
        "    q1 = line1[1]\n",
        "    p2 = line2[0]\n",
        "    q2 = line2[1]\n",
        "\n",
        "    o1 = get_orientation(p1, q1, p2)\n",
        "    o2 = get_orientation(p1, q1, q2)\n",
        "    o3 = get_orientation(p2, q2, p1)\n",
        "    o4 = get_orientation(p2, q2, q1)\n",
        "\n",
        "    if o1 != o2 and o3 != o4:\n",
        "        return True\n",
        "\n",
        "    if o1 == 0 and is_on_segment(p1, p2, q1):\n",
        "        return True\n",
        "\n",
        "    if o2 == 0 and is_on_segment(p1, q2, q1):\n",
        "        return True\n",
        "\n",
        "    if o3 == 0 and is_on_segment(p2, p1, q2):\n",
        "        return True\n",
        "\n",
        "    if o4 == 0 and is_on_segment(p2, q1, q2):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def _has_crossed_counting_line(bbox, line):\n",
        "    '''\n",
        "    Check if at least one edge of a bounding box is intersected by a counting line.\n",
        "    '''\n",
        "    x, y, w, h = bbox\n",
        "    bbox_line1 = [(x, y), (x + w, y)]\n",
        "    bbox_line2 = [(x + w, y), (x + w, y + h)]\n",
        "    bbox_line3 = [(x, y), (x, y + h)]\n",
        "    bbox_line4 = [(x, y + h), (x + w, y + h)]\n",
        "\n",
        "    if _line_segments_intersect(bbox_line1, line) or \\\n",
        "            _line_segments_intersect(bbox_line2, line) or \\\n",
        "            _line_segments_intersect(bbox_line3, line) or \\\n",
        "            _line_segments_intersect(bbox_line4, line):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def attempt_count(blob, counting_lines, counts):\n",
        "    for counting_line in counting_lines:\n",
        "        if _has_crossed_counting_line(blob.bounding_box, counting_line) and not blob.crossed_counting_line:\n",
        "            counts += 1\n",
        "            blob.crossed_counting_line = True\n",
        "            return blob, counts\n",
        "\n",
        "    return blob, counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDOo_Ij2Yo_g"
      },
      "source": [
        "# Visualizer\n",
        "- Function used to draw bounding boxes and texts in the output frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "frtD-ztVYr8O"
      },
      "outputs": [],
      "source": [
        "font = cv2.FONT_HERSHEY_DUPLEX\n",
        "line_type = cv2.LINE_AA\n",
        "\n",
        "def visualize(frame, blobs, fps, counts):\n",
        "    # Display tracker and fps\n",
        "    cv2.putText(frame, \"KCF Tracker\", (int(frame.shape[1]*0.05) ,int(frame.shape[0]*0.1)), font, 0.75, (50,170,50),2) \n",
        "    cv2.putText(frame, \"FPS : \" + str(int(fps)), (int(frame.shape[1]*0.05),int(frame.shape[0]*0.15)), font, 0.75, (50,170,50), 2)\n",
        "    \n",
        "    # draw and label blob bounding boxes\n",
        "    for _id, blob in blobs.items():\n",
        "        (x, y, w, h) = [int(v) for v in blob.bounding_box]\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        object_label = 'I: ' + _id[:8] \\\n",
        "            if blob.type is None \\\n",
        "            else 'I: {0}, T: {1} ({2})'.format(_id[:8], blob.type, str(blob.type_confidence)[:4])\n",
        "        cv2.putText(frame, object_label, (x, y - 5), font, 1, (255, 0, 0), 2, line_type)\n",
        "\n",
        "    # Draw counting line\n",
        "    line_thickness = 2\n",
        "    cv2.line(frame, (0, int(frame_shape[0]/2)), (frame_shape[1], int(frame_shape[0]/2)), (0, 255, 0), thickness=line_thickness)\n",
        "\n",
        "    # Draw\n",
        "    cv2.putText(frame, \"Count: {}\".format(counts), (int(frame.shape[1]*0.8), int(frame.shape[0]*0.1)), font, 1, (0, 0, 255), 2, line_type)\n",
        "    \n",
        "    \n",
        "    return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detect car color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "import operator\n",
        "import cv2\n",
        "\n",
        "\n",
        "# calculation of euclidead distance\n",
        "def calculateEuclideanDistance(variable1, variable2, length):\n",
        "    distance = 0\n",
        "    for x in range(length):\n",
        "        distance += pow(variable1[x] - variable2[x], 2)\n",
        "    return math.sqrt(distance)\n",
        "\n",
        "\n",
        "# get k nearest neigbors\n",
        "def kNearestNeighbors(training_feature_vector, testInstance, k):\n",
        "    distances = []\n",
        "    length = len(testInstance)\n",
        "    for x in range(len(training_feature_vector)):\n",
        "        dist = calculateEuclideanDistance(testInstance,\n",
        "                training_feature_vector[x], length)\n",
        "        distances.append((training_feature_vector[x], dist))\n",
        "    distances.sort(key=operator.itemgetter(1))\n",
        "    neighbors = []\n",
        "    for x in range(k):\n",
        "        neighbors.append(distances[x][0])\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "# votes of neighbors\n",
        "def responseOfNeighbors(neighbors):\n",
        "    all_possible_neighbors = {}\n",
        "    for x in range(len(neighbors)):\n",
        "        response = neighbors[x][-1]\n",
        "        if response in all_possible_neighbors:\n",
        "            all_possible_neighbors[response] += 1\n",
        "        else:\n",
        "            all_possible_neighbors[response] = 1\n",
        "    sortedVotes = sorted(all_possible_neighbors.items(),\n",
        "                         key=operator.itemgetter(1), reverse=True)\n",
        "    return sortedVotes[0][0]\n",
        "\n",
        "\n",
        "# Load image feature data to training feature vectors and test feature vector\n",
        "def loadDataset(\n",
        "    filename,\n",
        "    filename2,\n",
        "    training_feature_vector=[],\n",
        "    test_feature_vector=[],\n",
        "    ):\n",
        "    with open(filename) as csvfile:\n",
        "        lines = csv.reader(csvfile)\n",
        "        dataset = list(lines)\n",
        "        for x in range(len(dataset)):\n",
        "            for y in range(3):\n",
        "                dataset[x][y] = float(dataset[x][y])\n",
        "            training_feature_vector.append(dataset[x])\n",
        "\n",
        "    with open(filename2) as csvfile:\n",
        "        lines = csv.reader(csvfile)\n",
        "        dataset = list(lines)\n",
        "        for x in range(len(dataset)):\n",
        "            for y in range(3):\n",
        "                dataset[x][y] = float(dataset[x][y])\n",
        "            test_feature_vector.append(dataset[x])\n",
        "\n",
        "\n",
        "def knn_classifier(training_data, test_data):\n",
        "    training_feature_vector = []  # training feature vector\n",
        "    test_feature_vector = []  # test feature vector\n",
        "    loadDataset(training_data, test_data, training_feature_vector, test_feature_vector)\n",
        "    classifier_prediction = []  # predictions\n",
        "    k = 3  # K value of k nearest neighbor\n",
        "    for x in range(len(test_feature_vector)):\n",
        "        neighbors = kNearestNeighbors(training_feature_vector, test_feature_vector[x], k)\n",
        "        result = responseOfNeighbors(neighbors)\n",
        "        classifier_prediction.append(result)\n",
        "    return classifier_prediction[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import itemfreq\n",
        "\n",
        "def color_histogram_of_test_image(test_src_image):\n",
        "\n",
        "    # load the image\n",
        "    image = test_src_image\n",
        "\n",
        "    chans = cv2.split(image)\n",
        "    colors = ('b', 'g', 'r')\n",
        "    features = []\n",
        "    feature_data = ''\n",
        "    counter = 0\n",
        "    for (chan, color) in zip(chans, colors):\n",
        "        counter = counter + 1\n",
        "\n",
        "        hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
        "        # hist /= hist.sum() #normalize hist\n",
        "                \n",
        "        features.extend(hist)\n",
        "\n",
        "        # find the peak pixel values for R, G, and B\n",
        "        elem = np.argmax(hist)\n",
        "\n",
        "        if counter == 1:\n",
        "            blue = str(elem)\n",
        "        elif counter == 2:\n",
        "            green = str(elem)\n",
        "        elif counter == 3:\n",
        "            red = str(elem)\n",
        "            feature_data = red + ',' + green + ',' + blue\n",
        "            # print(feature_data)\n",
        "\n",
        "    with open('test.data', 'w') as myfile:\n",
        "        myfile.write(feature_data)\n",
        "\n",
        "\n",
        "def color_histogram_of_training_image(img_name):\n",
        "\n",
        "    # detect image color by using image file name to label training data\n",
        "    if 'red' in img_name:\n",
        "        data_source = 'red'\n",
        "    elif 'yellow' in img_name:\n",
        "        data_source = 'yellow'\n",
        "    elif 'white' in img_name:\n",
        "        data_source = 'white'\n",
        "    elif 'black' in img_name:\n",
        "        data_source = 'black'\n",
        "    elif 'blue' in img_name:\n",
        "        data_source = 'blue'\n",
        "    elif 'violet' in img_name:\n",
        "        data_source = 'violet'\n",
        "\n",
        "    # load the image\n",
        "    image = cv2.imread(img_name)\n",
        "\n",
        "    chans = cv2.split(image)\n",
        "    colors = ('b', 'g', 'r')\n",
        "    features = []\n",
        "    feature_data = ''\n",
        "    counter = 0\n",
        "    for (chan, color) in zip(chans, colors):\n",
        "        counter = counter + 1\n",
        "\n",
        "        hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
        "        features.extend(hist)\n",
        "\n",
        "        # find the peak pixel values for R, G, and B\n",
        "        elem = np.argmax(hist)\n",
        "\n",
        "        if counter == 1:\n",
        "            blue = str(elem)\n",
        "        elif counter == 2:\n",
        "            green = str(elem)\n",
        "        elif counter == 3:\n",
        "            red = str(elem)\n",
        "            feature_data = red + ',' + green + ',' + blue\n",
        "\n",
        "    with open('training.data', 'a') as myfile:\n",
        "        myfile.write(feature_data + ',' + data_source + '\\n')\n",
        "\n",
        "\n",
        "def training():\n",
        "\n",
        "    # red color training images\n",
        "    for f in os.listdir('./training_dataset/red'):\n",
        "        color_histogram_of_training_image('./training_dataset/red/' + f)\n",
        "\n",
        "    # yellow color training images\n",
        "    for f in os.listdir('./training_dataset/yellow'):\n",
        "        color_histogram_of_training_image('./training_dataset/yellow/' + f)\n",
        "\n",
        "    # white color training images\n",
        "    for f in os.listdir('./training_dataset/white'):\n",
        "        color_histogram_of_training_image('./training_dataset/white/' + f)\n",
        "\n",
        "    # black color training images\n",
        "    for f in os.listdir('./training_dataset/black'):\n",
        "        color_histogram_of_training_image('./training_dataset/black/' + f)\n",
        "\n",
        "    # blue color training images\n",
        "    for f in os.listdir('./training_dataset/blue'):\n",
        "        color_histogram_of_training_image('./training_dataset/blue/' + f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict car color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_car_color_predictions(cars):\n",
        "    predictions = [] # (car_id, predicted_label)\n",
        "\n",
        "    for (car_id, car_img) in cars:\n",
        "        color_histogram_of_test_image(car_img)\n",
        "        prediction = knn_classifier('training.data', 'test.data')\n",
        "\n",
        "        predictions.append((car_id, car_img, prediction))\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_car_counted(blobs_list, cars_counted):\n",
        "    cars = [] # (car_id, car_img) \n",
        "\n",
        "    for blob in blobs_list:\n",
        "        blob_id = blob[0]\n",
        "        blob_obj = blob[1]\n",
        "        \n",
        "        if(blob_id not in cars_counted and blob_obj.crossed_counting_line):\n",
        "            cars_counted.append(blob_id)\n",
        "\n",
        "            x = int(blob_obj.bounding_box[0] - (blob_obj.bounding_box[0]+blob_obj.bounding_box[2])*0.04)\n",
        "            y = int(blob_obj.bounding_box[1] - (blob_obj.bounding_box[1]+blob_obj.bounding_box[3])*0.08)\n",
        "            w = int(blob_obj.bounding_box[0]+blob_obj.bounding_box[2] + (blob_obj.bounding_box[0]+blob_obj.bounding_box[2])*0.04)\n",
        "            h = int(blob_obj.bounding_box[1]+blob_obj.bounding_box[3] + (blob_obj.bounding_box[1]+blob_obj.bounding_box[3])*0.08)\n",
        "            car_img = frame[y:h, x:w]\n",
        "\n",
        "            cars.append((blob_id, car_img))\n",
        "            \n",
        "    return cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kP5kgHsW-Wc"
      },
      "source": [
        "# Main Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "(540, 960, 3)\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('Data/Traffic_Example.mp4')\n",
        "print(cap.isOpened())\n",
        "\n",
        "car_cascade = cv2.CascadeClassifier('./car.xml')\n",
        "\n",
        "cars_counted = []\n",
        "cars_already_counted = 0\n",
        "\n",
        "blobs = {}\n",
        "max_consecutive_failures = 2\n",
        "detection_interval = 5\n",
        "\n",
        "ret, frame = cap.read()\n",
        "\n",
        "frame = cv2.resize(frame, (960, 540))\n",
        "\n",
        "frame_shape = frame.shape\n",
        "print(frame_shape)\n",
        "counting_lines = [\n",
        "    [(0, int(frame_shape[0]/2)), (frame_shape[1], int(frame_shape[0]/2))]\n",
        "]\n",
        "counts = 0\n",
        "\n",
        "output_video = cv2.VideoWriter(\"./Output/objectCounter.avi\",\n",
        "    cv2.VideoWriter_fourcc(*'MJPG'), \n",
        "    30,\n",
        "    (frame.shape[1], frame.shape[0])\n",
        ")\n",
        "\n",
        "_bounding_boxes, _classes, _confidences = get_bounding_boxes(frame)\n",
        "blobs = add_new_blobs(_bounding_boxes, _classes, _confidences, blobs, frame, max_consecutive_failures)\n",
        "\n",
        "frame_count = 0\n",
        "while(cap.isOpened()):\n",
        "\n",
        "    frame = cv2.resize(frame, (960, 540))\n",
        "\n",
        "    # Start timer\n",
        "    timer = cv2.getTickCount()\n",
        "    # Calculate Frames per second (FPS)\n",
        "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
        "\n",
        "    # update blob trackers\n",
        "    blobs_list = list(blobs.items())\n",
        "    blobs_list = [update_blob_tracker(blob, blob_id, frame) for blob_id, blob in blobs_list]\n",
        "    blobs = dict(blobs_list)\n",
        "\n",
        "    # Count vehicles\n",
        "    for blob_id, blob in blobs_list:\n",
        "        # count object if it has crossed a counting line\n",
        "        blob, counts = attempt_count(blob, counting_lines, counts)\n",
        "        blobs[blob_id] = blob\n",
        "        # remove blob if it has reached the limit for tracking failures\n",
        "        if blob.num_consecutive_tracking_failures >= max_consecutive_failures:\n",
        "            del blobs[blob_id]\n",
        "\n",
        "    # detect objects\n",
        "    if frame_count % detection_interval == 0:\n",
        "        # rerun detection\n",
        "        _bounding_boxes, _classes, _confidences = get_bounding_boxes(frame)\n",
        "\n",
        "        blobs = add_new_blobs(\n",
        "            _bounding_boxes, _classes, _confidences, \n",
        "            blobs, frame, max_consecutive_failures)\n",
        "        blobs = remove_duplicates(blobs)\n",
        "\n",
        "    # Print blobs\n",
        "    if(counts > cars_already_counted):\n",
        "        cars_already_counted = counts\n",
        "\n",
        "        cars = get_car_counted(blobs_list, cars_counted)\n",
        "\n",
        "        car_color_predictions = get_car_color_predictions(cars)\n",
        "\n",
        "        for (car_id, car_img, color_predicted) in car_color_predictions:\n",
        "            cv2.imwrite('./CarsCounted/'+color_predicted+'_'+car_id+'.png', car_img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # for blob in blobs_list:\n",
        "        #     if(blob[0] not in cars_counted and blob[1].crossed_counting_line):\n",
        "        #         cars_counted.append(blob[0])\n",
        "\n",
        "        #         x = int(blob[1].bounding_box[0] - (blob[1].bounding_box[0]+blob[1].bounding_box[2])*0.04)\n",
        "        #         y = int(blob[1].bounding_box[1] - (blob[1].bounding_box[1]+blob[1].bounding_box[3])*0.08)\n",
        "        #         w = int(blob[1].bounding_box[0]+blob[1].bounding_box[2] + (blob[1].bounding_box[0]+blob[1].bounding_box[2])*0.04)\n",
        "        #         h = int(blob[1].bounding_box[1]+blob[1].bounding_box[3] + (blob[1].bounding_box[1]+blob[1].bounding_box[3])*0.08)\n",
        "        #         carImg = frame[\n",
        "        #             y:h,\n",
        "        #             x:w\n",
        "        #         ]\n",
        "        #         # Prediction\n",
        "        #         color_histogram_of_test_image(cropped_image)\n",
        "        #         prediction = knn_classifier('training.data', 'test.data')\n",
        "        #         cv2.imwrite('./CarsCounted/'+prediction+blob[0]+'.png', cropped_image)\n",
        "\n",
        "    output_frame = visualize(frame, blobs, fps, counts)\n",
        "\n",
        "    # Record frames\n",
        "    output_video.write(output_frame)\n",
        "\n",
        "    # Display result ----------------------------------------------------------------------------\n",
        "    cv2.imshow(\"output_frame\", output_frame)\n",
        "    frame_count += 1\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ComputerVisionChallenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
